{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here's the description from the paper</p>\n",
    "<img src=\"EEGNet.png\" style=\"width: 700px; float:left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C', 'D', 'E', 'F'], ['G', 'H', 'I', 'J', 'K', 'L'], ['M', 'N', 'O', 'P', 'Q', 'R'], ['S', 'T', 'U', 'V', 'W', 'X'], ['Y', 'Z', '1', '2', '3', '4'], ['5', '6', '7', '8', '9', '_']]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEST_A = 'data/BCI_Comp_III_Wads_2004/Subject_A_Test1.mat'\n",
    "TEST_B = 'data/BCI_Comp_III_Wads_2004/Subject_B_Test1.mat'\n",
    "\n",
    "TRUE_LABELS_A = 'WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU'\n",
    "TRUE_LABELS_B = 'MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR'\n",
    "\n",
    "MATRIX = ['abcdef',\n",
    "          'ghijkl',\n",
    "          'mnopqr',\n",
    "          'stuvwx',\n",
    "          'yz1234',\n",
    "          '56789_']\n",
    "\n",
    "screen=[['A','B','C','D','E','F'],\n",
    "            ['G','H','I','J','K','L'],\n",
    "            ['M','N','O','P','Q','R'],\n",
    "            ['S','T','U','V','W','X'],\n",
    "            ['Y','Z','1','2','3','4'],\n",
    "            ['5','6','7','8','9','_']]\n",
    "\n",
    "print (screen)\n",
    "print (len(screen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(SUBJECT,flag):\n",
    "    \n",
    "    data=scipy.io.loadmat(SUBJECT)\n",
    "    \n",
    "    #print ('Subject A dataa',data)\n",
    "    Signal=np.float32(data['Signal'])\n",
    "    #print ('signal',Signal, Signal.shape)\n",
    "\n",
    "    Flashing=np.float32(data['Flashing'])\n",
    "    #print ('flashing',Flashing, Flashing.shape)\n",
    "\n",
    "    StimulusCode=np.float32(data['StimulusCode'])\n",
    "    #print ('Stimulus COde',StimulusCode,StimulusCode.shape)\n",
    "    if flag==0:\n",
    "        StimulusType=np.float32(data['StimulusType'])\n",
    "        #print ('Stimulus type',StimulusType,StimulusType.shape)\n",
    "\n",
    "        Target=data['TargetChar']# array([ 'EAEVQTDOJG8RBRGONCEDHCTUIDBPUHMEM6OUXOCFOUKWA4VJEFRZROLHYNQDW_EKTLBWXEPOUIKZERYOOTHQI'],4\n",
    "        #print ('Target char for subjectA',Target)\n",
    "\n",
    "        return Signal,Flashing,StimulusCode,StimulusType,Target\n",
    "\n",
    "    else:\n",
    "         return Signal,Flashing,StimulusCode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_Signal_A1,test_Flashing_A1,test_StimulusCode_A1=load_dataset(TEST_A,1)\n",
    "test_char_size=test_Signal_A1.shape[0]\n",
    "#############################################################################################\n",
    "test_Signal_B1,test_Flashing_B1,test_StimulusCode_B1=load_dataset(TEST_B,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DOWNSAMPLING THE SIGNAL\n",
    "\n",
    "secs = test_Signal_A1.shape[1]/240# Number of seconds in signal\n",
    "samps = int(secs*120)     # Number of samples to downsample\n",
    "\n",
    "Signal_A=np.zeros([test_Signal_A1.shape[0],samps,64])\n",
    "Flashing_A=np.zeros([test_Signal_A1.shape[0],samps])\n",
    "StimulusCode_A=np.zeros([test_Signal_A1.shape[0],samps])\n",
    "#StimulusType_A=np.zeros([Signal_A_240.shape[0],samps])\n",
    "\n",
    "Signal_B=np.zeros([test_Signal_B1.shape[0],samps,64])\n",
    "Flashing_B=np.zeros([test_Signal_B1.shape[0],samps])\n",
    "StimulusCode_B=np.zeros([test_Signal_B1.shape[0],samps])\n",
    "#StimulusType_B=np.zeros([test_Signal_B1.shape[0],samps])\n",
    "\n",
    "\n",
    "for i in range(0,test_Signal_B1.shape[0]):\n",
    "    Signal_A[i,:,:] = scipy.signal.resample(test_Signal_A1[i,:,:], int(samps))\n",
    "    Signal_B[i,:,:] = scipy.signal.resample(test_Signal_B1[i,:,:], int(samps))\n",
    "    #print (Flashing_A_240[i,:],Flashing_A_240[i,:].shape)\n",
    "    Flashing_A[i,:] = abs(np.round(scipy.signal.resample(test_Flashing_A1[i,:], int(samps))))\n",
    "    #print (Flashing_A[i,:],Flashing_A[i,:].shape)\n",
    "    StimulusCode_A[i,:] = abs(np.floor(scipy.signal.resample(test_StimulusCode_A1[i,:], int(samps)))).astype('int8')\n",
    "    #print (StimulusCode_A[i,:])\n",
    "    #StimulusType_A[i,:] = abs(np.floor(scipy.signal.resample(StimulusType_A_240[i,:], int(samps))))\n",
    "    #print (StimulusType_A[i,:])\n",
    "    \n",
    "    Flashing_B[i,:] = abs(np.round(scipy.signal.resample(test_Flashing_B1[i,:], int(samps))))\n",
    "    StimulusCode_B[i,:] = abs(np.floor(scipy.signal.resample(test_StimulusCode_B1[i,:], int(samps))))\n",
    "    #StimulusType_B[i,:] = abs(np.floor(scipy.signal.resample(StimulusType_B_240[i,:], int(samps))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_Signal_A=Signal_A\n",
    "test_Signal_B=Signal_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_Flashing_A=Flashing_A\n",
    "test_Flashing_B=Flashing_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_StimulusCode_B=StimulusCode_B\n",
    "test_StimulusCode_A=StimulusCode_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "### DEFINE P300 WIndow size\n",
    "window=(48/2)  # take a window to get no of datapoints corresponding to 600 ms after onset of stimuli \n",
    "T=int(3*window)\n",
    "print(window/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for all characters (100, 12, 15, 72, 64)\n",
      "Splitting P300 and non-P300 dataset...\n",
      "(100, 2, 72, 64)\n",
      "(100, 10, 72, 64)\n",
      "TestsetA (100, 12, 72, 64)\n",
      "\n",
      "testSetB\n",
      "Response for all characters (100, 12, 15, 72, 64)\n",
      "Splitting P300 and non-P300 dataset...\n",
      "(100, 2, 72, 64)\n",
      "(100, 10, 72, 64)\n",
      "TestsetB (100, 12, 72, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### CODE TO FORMAT TEST DATA\n",
    "def format_test_data(Signal,Flashing,StimulusCode,Target):\n",
    "    test_char_size=Signal.shape[0]\n",
    "    responses=np.zeros([test_char_size,12,15,T,64])\n",
    "    \n",
    "    for epoch in range(0,Signal.shape[0]):\n",
    "        count=1;\n",
    "        rowcolcnt=np.zeros(12)\n",
    "        for n in range(1,Signal.shape[1]):\n",
    "            # detect location of sample immediately after the stimuli\n",
    "            if Flashing[epoch,n]==0 and Flashing[epoch,n-1]==1:\n",
    "                rowcol=int(StimulusCode[epoch,n-1])-1\n",
    "                #print (Signal[epoch,n:n+window,:].shape)\n",
    "               # print (rowcolcnt[int(rowcol)])\n",
    "                responses[epoch,int(rowcol),int(rowcolcnt[int(rowcol)]),:,:]=Signal[epoch,n-int(window/2):n+ int(2.5*window),:]\n",
    "                rowcolcnt[rowcol]=rowcolcnt[rowcol]+1\n",
    "                #print (rowcolcnt)\n",
    "        #print (epoch)\n",
    "    print ('Response for all characters',responses.shape)\n",
    "\n",
    "    #####################################################################################################################\n",
    "    ### Taking average over 15 instances of the 12 stimuli, comment to check performance and increase the dataset size- TO DO\n",
    "    testset=np.mean(responses, axis=2)\n",
    "    #print ('Testset',testset.shape)\n",
    "    Target=list(Target)\n",
    "    #target_ohe=np.zeros([len(Target[0]),36])\n",
    "   # print (Target[0])\n",
    "    stimulus_indices=[]\n",
    "    for n_char in range(0,len(Target)):  #character epochs\n",
    "\n",
    "        #print (Target[n_char])\n",
    "        #vv=np.where(screen==str(Target[0][n_char]))\n",
    "        #print (vv)\n",
    "        #[row,col]\n",
    "       \n",
    "        for row in range(0,6):\n",
    "            for col in range(0,6):\n",
    "                #print (screen[row][col])\n",
    "                if (Target[n_char]) is (screen[row][col]):\n",
    "                    ind=[row+7,col+1]\n",
    "                    stimulus_indices.append(ind)\n",
    "                    #print (ind)\n",
    "            ##        print ('here',stimulus_indices[n_char])\n",
    "        \n",
    "   # print (stimulus_indices)\n",
    "    print ('Splitting P300 and non-P300 dataset...')\n",
    "    # iterate over the 2nd dimension of trainset:trainset (train_char_size, 12, 42, 64) and split as train_char_size*2*42*64 and train_char_size*10*42*64\n",
    "    \n",
    "    test_P300_dataset=np.zeros([test_char_size,2,T,64])\n",
    "    test_non_P300_dataset=np.zeros([test_char_size,10,T,64])\n",
    "\n",
    "    for char_epoch in range(0,testset.shape[0]):\n",
    "        # choose the i,j out of the 2nd dimension of trainset where i,j comes from stimulus_indices[char_epoch]\n",
    "        ind_1=stimulus_indices[char_epoch][0]\n",
    "        ind_2=stimulus_indices[char_epoch][1]\n",
    "        #print (ind_1,ind_2)\n",
    "        l=0\n",
    "        for index in range(0,12):\n",
    "            if index==ind_1-1 or index==ind_2-1 :\n",
    "                test_P300_dataset[char_epoch,0,:,:]=testset[char_epoch,ind_1-1,:,:]\n",
    "                test_P300_dataset[char_epoch,1,:,:]=testset[char_epoch,ind_2-1,:,:]\n",
    "\n",
    "            else:\n",
    "                #print ('here')\n",
    "                #print (index)\n",
    "                test_non_P300_dataset[char_epoch,l,:,:]=testset[char_epoch,index,:,:]\n",
    "               # targets_A[char_epoch,index]=0\n",
    "\n",
    "                l=l+1\n",
    "\n",
    "    #print (np.all(P300_dataset[0,0,:,:])==np.all(trainset[0,5,:,:]))\n",
    "    print (test_P300_dataset.shape)\n",
    "    print (test_non_P300_dataset.shape)\n",
    "    \n",
    "    return testset, test_P300_dataset, test_non_P300_dataset\n",
    "\n",
    "testset_A,test_P300_dataset_A, test_non_P300_dataset_A=format_test_data(test_Signal_A,test_Flashing_A,test_StimulusCode_A, TRUE_LABELS_A)\n",
    "#testset_A=testset_A.reshape([test_char_size*12,T,64])\n",
    "print ('TestsetA',testset_A.shape)\n",
    "print ('\\ntestSetB')\n",
    "testset_B,test_P300_dataset_B, test_non_P300_dataset_B=format_test_data(test_Signal_B,test_Flashing_B,test_StimulusCode_B,TRUE_LABELS_B)\n",
    "#testset_B=testset_B.reshape([test_char_size*12,T,64])\n",
    "print ('TestsetB',testset_B.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject A\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Test set of P300 samples\n",
      "(200, 72, 64) (200, 1)\n",
      "\n",
      "Testg set of non-P300 samples\n",
      "(1000, 72, 64) (1000, 1)\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('For subject A')\n",
    "    \n",
    "P300_test_A=np.reshape(test_P300_dataset_A,[100*2,72,64])\n",
    "P300_test_label_A=np.ones([P300_test_A.shape[0],1]).astype('int8')\n",
    "#test_label_A[:,0:2]=1 ; test_label_A[:,2:12]=0\n",
    "P300_test_label_A=P300_test_label_A\n",
    "\n",
    "#test_label_A=np.zeros([test_char_size,12])\n",
    "#test_label_A[:,0:2]=1 ; test_label_A[:,2:12]=0\n",
    "\n",
    "non_P300_test_A=np.reshape(test_non_P300_dataset_A,[100*10,72,64])\n",
    "non_P300_test_label_A=np.zeros([non_P300_test_A.shape[0],1]).astype('int8')\n",
    "non_P300_test_label_A=non_P300_test_label_A\n",
    "\n",
    "#=create_labels(np.reshape(P300_dataset_A,[train_char_size*2,T,64]),np.reshape(targets_A[:,0:2],[train_char_size*2,1]))\n",
    "\n",
    "#non_P300_train_A,non_P300_hold_A, non_P300_train_label_A, non_P300_hold_label_A=create_subset(np.reshape(non_P300_dataset_A,[train_char_size*10,T,64]),np.reshape(targets_A[:,2:12],[train_char_size*10,1]))\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "print ('Test set of P300 samples')\n",
    "print (P300_test_A.shape,P300_test_label_A.shape)   \n",
    "\n",
    "\n",
    "print ('\\nTestg set of non-P300 samples')\n",
    "print (non_P300_test_A.shape,non_P300_test_label_A.shape)  \n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for test subject B\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Test set of P300 samples\n",
      "(200, 72, 64) (200, 1)\n",
      "\n",
      "Testg set of non-P300 samples\n",
      "(1000, 72, 64) (1000, 1)\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHANGE A to B in following cell\n",
    "print ('for test subject B')\n",
    "P300_test_B=np.reshape(test_P300_dataset_B,[100*2,72,64])\n",
    "P300_test_label_B=np.ones([P300_test_B.shape[0],1]).astype('int8')\n",
    "#test_label_B[:,0:2]=1 ; test_label_B[:,2:12]=0\n",
    "P300_test_label_B=P300_test_label_B\n",
    "\n",
    "#test_label_B=np.zeros([test_char_size,12])\n",
    "#test_label_B[:,0:2]=1 ; test_label_B[:,2:12]=0\n",
    "\n",
    "non_P300_test_B=np.reshape(test_non_P300_dataset_B,[100*10,72,64])\n",
    "non_P300_test_label_B=np.zeros([non_P300_test_B.shape[0],1]).astype('int8')\n",
    "non_P300_test_label_B=non_P300_test_label_B\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "print ('Test set of P300 samples')\n",
    "print (P300_test_B.shape,P300_test_label_B.shape)   \n",
    "\n",
    "\n",
    "print ('\\nTestg set of non-P300 samples')\n",
    "print (non_P300_test_B.shape,non_P300_test_label_B.shape)  \n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "print('----------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------HOLD AND TRAIN DATASET_CNN READY----------------------------------------------\n",
      "(1200, 72, 64) (1200, 1)\n",
      "-------------------------HOLD AND TRAIN DATASET_CNN READY----------------------------------------------\n",
      "(1200, 72, 64) (1200, 1)\n"
     ]
    }
   ],
   "source": [
    "def shuffle(trainIm_rem,trainL_rem): \n",
    "    \n",
    "    \n",
    "    NtrainIm_hold = []\n",
    "    NtrainL_hold = []\n",
    "  \n",
    "    R = random.sample(range(0, trainIm_rem.shape[0]),trainIm_rem.shape[0])\n",
    "\n",
    "    for k in R:\n",
    "        #print (k)\n",
    "        NtrainIm_hold.append(trainIm_rem[k,:,:])\n",
    "        NtrainL_hold.append(trainL_rem[k,:])\n",
    "    \n",
    "    return np.array(NtrainIm_hold),np.array(NtrainL_hold)\n",
    "\n",
    "# AGAIN IGNORE THE NAMING CONVENTION WHICH IS BY DEFAULT A\n",
    "\n",
    "def create_final_testset(P300_hold_A,non_P300_hold_A,P300_hold_label_A,non_P300_hold_label_A):\n",
    "\n",
    "    #######################################################\n",
    "    #Combine the dataset:\n",
    "     \n",
    "    h1=P300_hold_label_A.shape[0] + non_P300_hold_label_A.shape[0] #111\n",
    "    h2= P300_hold_label_A.shape[0] #18\n",
    "\n",
    "    dataset_A_hold=np.zeros([h1,T,64])\n",
    "    dataset_A_hold[0:h2,:,:]=P300_hold_A\n",
    "    dataset_A_hold[h2:h1:,:]=non_P300_hold_A\n",
    "    targets_A_hold=np.zeros([h1,1])\n",
    "    targets_A_hold[0:h2,:]=1\n",
    "\n",
    "    #print(targets_A_hold.shape)\n",
    "\n",
    "    ### SHUFFLE ABOVE DATASET and LABELS\n",
    "    print ('-------------------------HOLD AND TRAIN DATASET_CNN READY----------------------------------------------')\n",
    "    dataset_A_hold,targets_A_hold=shuffle(dataset_A_hold,targets_A_hold)\n",
    "    print (dataset_A_hold.shape,targets_A_hold.shape)\n",
    "  ################################\n",
    "\n",
    "    return dataset_A_hold,targets_A_hold  \n",
    "\n",
    "dataset_A_test,targets_A_test = create_final_testset(P300_test_A,non_P300_test_A,P300_test_label_A,non_P300_test_label_A)\n",
    "dataset_B_test,targets_B_test = create_final_testset(P300_test_B,non_P300_test_B,P300_test_label_B,non_P300_test_label_B)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_A_test1={};dataset_A_test1['data']=dataset_A_test\n",
    "dataset_B_test1={};dataset_B_test1['data']=dataset_B_test\n",
    "\n",
    "targets_A_test1={};targets_A_test1['labels']=targets_A_test\n",
    "targets_B_test1={};targets_B_test1['labels']=targets_B_test\n",
    "\n",
    "\n",
    "scipy.io.savemat('test_set_A_d_proc.mat',dataset_A_test1)\n",
    "scipy.io.savemat('test_set_B_d_proc.mat',dataset_B_test1)\n",
    "scipy.io.savemat('true_labels_A_d_proc.mat',targets_A_test1)\n",
    "scipy.io.savemat('true_labels_B_d_proc.mat',targets_B_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
